{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder,  MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Loading Dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Identifying Duplicates\n",
    "print(f\"Duplicates in Train Dataset is:{train_df.duplicated().sum()}\")\n",
    "print(f\"Duplicates in Test Dataset is:{test_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Checking data types \n",
    "print(\"Data Types of features of Training Data is:\")\n",
    "print(train_df.dtypes)\n",
    "print(\"\\nData types of features of Testing Data is:\")\n",
    "print(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Looking for missing values\n",
    "df1 = (train_df.isnull().sum()[train_df.isnull().sum()>0]).to_frame().rename(columns={0:\"Number of Missing values\"})\n",
    "df1[\"% of Missing Values\"] = round((100*train_df.isnull().sum()[train_df.isnull().sum()>0]/len(train_df)),2)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (test_df.isnull().sum()[test_df.isnull().sum()>0]).to_frame().rename(columns={0:\"Number of Missing values\"})\n",
    "df2[\"% of Missing Values\"] = round((100*test_df.isnull().sum()[test_df.isnull().sum()>0]/len(test_df)),2).values\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Visualizing: age\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.histplot(x=train_df[\"Age\"],hue=\"Transported\",data=train_df,palette=\"Set1\")\n",
    "plt.title(\"Age Feature Distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Visualizing: RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "exp_cols = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "for idx,column in enumerate(exp_cols):\n",
    "    plt.subplot(3,2,idx+1)\n",
    "    sns.histplot(x=column, hue=\"Transported\", data=train_df,bins=30,palette=\"Set1\")\n",
    "    plt.title(f\"{column} Distribution\")\n",
    "    plt.ylim(0,100)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Visualizing(categrical): RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "cat_cols = [\"HomePlanet\",\"CryoSleep\",\"Destination\",\"VIP\"]\n",
    "\n",
    "plt.figure(figsize=(12,20))\n",
    "for idx,column in enumerate(cat_cols):\n",
    "    plt.subplot(4,1,idx+1)\n",
    "    sns.countplot(x=column, hue=\"Transported\", data=train_df, palette=\"Set1\")\n",
    "    plt.title(f\"{column} Distribution\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#II Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 PassengerId--> Group_Size, Travelling_Solo\n",
    "def passengerid_new_features(df):\n",
    "    \n",
    "    #Splitting \"PassengerId\" column.\n",
    "    df[\"Group\"] = df[\"PassengerId\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    df[\"Member\"] =df[\"PassengerId\"].apply(lambda x: x.split(\"_\")[1])\n",
    "    \n",
    "    #Grouping the \"Group\" feature wrt \"member\" feature to check which group is travelling with how many members\n",
    "    x = df.groupby(\"Group\")[\"Member\"].count().sort_values()\n",
    "    \n",
    "    #set of group values with more than 1 members.\n",
    "    y = set(x[x>1].index)\n",
    "    \n",
    "    # New feature \"Solo\" , indicates whether the person is travelling solo or not.\n",
    "    df[\"Travelling_Solo\"] = df[\"Group\"].apply(lambda x: x not in y)\n",
    "    \n",
    "    # New feature \"Group_size\" which will indicate each group's number of members.\n",
    "    df[\"Group_Size\"]=0\n",
    "    for i in x.items():\n",
    "        df.loc[df[\"Group\"]==i[0],\"Group_Size\"]=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerid_new_features(train_df)\n",
    "passengerid_new_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Group & Member feature\n",
    "train_df.drop(columns=[\"Group\",\"Member\"],inplace=True)\n",
    "test_df.drop(columns=[\"Group\",\"Member\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing: Group_Size, Travelling_Solo \n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=\"Group_Size\", hue=\"Transported\", data=train_df,palette=\"Set1\")\n",
    "plt.title(\"Group_Size vs Transported\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=\"Travelling_Solo\", hue=\"Transported\", data=train_df,palette=\"Set1\")\n",
    "plt.title(\"Travelling Solo vs Transported\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Cabin-->Cabin_Deck, Cabin_Number, Cabin_Side \n",
    "def cabin_new_feature(df):\n",
    "    # Ensure all values in Cabin are strings\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].fillna(\"np.nan/np.nan/np.nan\").astype(str)\n",
    "    \n",
    "    #Handling NaN values while splitting\n",
    "    df[\"Cabin\"].fillna(\"np.nan/np.nan/np.nan\")  \n",
    "    \n",
    "    df[\"Cabin_Deck\"] = df[\"Cabin\"].apply(lambda x: x.split(\"/\")[0])\n",
    "    df[\"Cabin_Number\"]  = df[\"Cabin\"].apply(lambda x: x.split(\"/\")[1])\n",
    "    df[\"Cabin_Side\"] = df[\"Cabin\"].apply(lambda x: x.split(\"/\")[2])\n",
    "    \n",
    "    #Replacing string nan values to numpy nan values.\n",
    "    cols = [\"Cabin_Deck\",\"Cabin_Number\",\"Cabin_Side\"]\n",
    "    df[cols]=df[cols].replace(\"np.nan\",np.nan)\n",
    "\n",
    "    # Convert Cabin_Number to numeric\n",
    "    df[\"Cabin_Number\"] = pd.to_numeric(df[\"Cabin_Number\"], errors=\"coerce\")\n",
    "    \n",
    "    #Filling Missing Values in new features created.\n",
    "    df[\"Cabin_Deck\"].fillna(df[\"Cabin_Deck\"].mode()[0])\n",
    "    df[\"Cabin_Side\"].fillna(df[\"Cabin_Side\"].mode()[0])\n",
    "    df[\"Cabin_Number\"].fillna(df[\"Cabin_Number\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_new_feature(train_df)\n",
    "cabin_new_feature(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing: Cabin_Deck, Cabin_Side\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=\"Cabin_Deck\",hue=\"Transported\", data=train_df, palette=\"Set1\")\n",
    "plt.title(\"Cabin_Deck Distribution\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=\"Cabin_Side\", hue=\"Transported\", data=train_df, palette=\"Set1\")\n",
    "plt.title(\"Cabin_Side Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REVISIT 1 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
    "# Fill missing values with the median before converting to integers\n",
    "train_df[\"Cabin_Number\"] = train_df[\"Cabin_Number\"].fillna(train_df[\"Cabin_Number\"].median()).astype(int)\n",
    "test_df[\"Cabin_Number\"] = test_df[\"Cabin_Number\"].fillna(test_df[\"Cabin_Number\"].median()).astype(int)\n",
    "# NaN type casting error\n",
    "\n",
    "\n",
    "# Convert Cabin_Number to integer type\n",
    "train_df[\"Cabin_Number\"]=train_df[\"Cabin_Number\"].astype(int)\n",
    "test_df[\"Cabin_Number\"]=test_df[\"Cabin_Number\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some analysis on Cabin_Number\n",
    "print(\"Total Unique values present in Cabin_Number feature is:\",train_df[\"Cabin_Number\"].nunique())\n",
    "print(\"The Mean of Cabin_Number Feature is: \",train_df[\"Cabin_Number\"].mean())\n",
    "print(\"The Median of Cabin_Number Feature is:\",train_df[\"Cabin_Number\"].median())\n",
    "print(\"The Minimum value of Cabin_Number feature is:\",train_df[\"Cabin_Number\"].min())\n",
    "print(\"The Maximum value of Cabin_number Feature is:\",train_df[\"Cabin_Number\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing: Cabin_Number\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.histplot(x=\"Cabin_Number\",data=train_df,hue=\"Transported\",palette=\"Set1\")\n",
    "plt.title(\"Cabin_Number Distribution\")\n",
    "plt.xticks(list(range(0,1900,300)))\n",
    "plt.vlines(300,ymin=0,ymax=550,color=\"black\")\n",
    "plt.vlines(600,ymin=0,ymax=550,color=\"black\")\n",
    "plt.vlines(900,ymin=0,ymax=550,color=\"black\")\n",
    "plt.vlines(1200,ymin=0,ymax=550,color=\"black\")\n",
    "plt.vlines(1500,ymin=0,ymax=550,color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Cabin_Number-->Cabin_Regions\n",
    "def cabin_regions(df):\n",
    "    df[\"Cabin_Region1\"] = (df[\"Cabin_Number\"]<300)\n",
    "    df[\"Cabin_Region2\"] = (df[\"Cabin_Number\"]>=300) & (df[\"Cabin_Number\"]<600)\n",
    "    df[\"Cabin_Region3\"] = (df[\"Cabin_Number\"]>=600) & (df[\"Cabin_Number\"]<900)\n",
    "    df[\"Cabin_Region4\"] = (df[\"Cabin_Number\"]>=900) & (df[\"Cabin_Number\"]<1200)\n",
    "    df[\"Cabin_Region5\"] = (df[\"Cabin_Number\"]>=1200) & (df[\"Cabin_Number\"]<1500)\n",
    "    df[\"Cabin_Region6\"] = (df[\"Cabin_Number\"]>=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_regions(train_df)\n",
    "cabin_regions(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Cabin_Number Feature\n",
    "train_df.drop(columns=[\"Cabin_Number\"],inplace=True)\n",
    "test_df.drop(columns=[\"Cabin_Number\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing: Cabin_Regions\n",
    "cols = [\"Cabin_Region1\",\"Cabin_Region2\",\"Cabin_Region3\",\"Cabin_Region4\",\"Cabin_Region5\",\"Cabin_Region6\"]\n",
    "\n",
    "plt.figure(figsize=(20,25))\n",
    "for idx,value in enumerate(cols):\n",
    "    plt.subplot(4,2,idx+1)\n",
    "    sns.countplot(x=value, hue=\"Transported\", data=train_df, palette=\"Set2\")\n",
    "    plt.title(f\"{value} Distribution\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Age-->Age_Group\n",
    "def age_group(df):\n",
    "    age_group  = []\n",
    "    for i in df[\"Age\"]:\n",
    "        if i<=12:\n",
    "            age_group.append(\"Age_0-12\")\n",
    "        elif (i>12 and i<=18):\n",
    "            age_group.append(\"Age_13-18\")\n",
    "        elif (i>18 and i<=25):\n",
    "            age_group.append(\"Age_19-25\")\n",
    "        elif (i>25 and i<=32):\n",
    "            age_group.append(\"Age_26-32\")\n",
    "        elif (i>32 and i<=50):\n",
    "            age_group.append(\"Age_33_50\")\n",
    "        elif (i>50):\n",
    "            age_group.append(\"age_50+\")\n",
    "        else:\n",
    "            age_group.append(np.nan)\n",
    "        \n",
    "    df[\"Age Group\"] = age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group(train_df)\n",
    "age_group(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing: Age_Group\n",
    "order = sorted(train_df[\"Age Group\"].value_counts().keys().to_list())\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(x=\"Age Group\",hue=\"Transported\", data=train_df, palette=\"Set2\",order=order)\n",
    "plt.title(\"Age Group Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 RoomService, FoodCourt, ShoppingMall, Spa, VRDeck --> Total Expenditure\n",
    "exp_cols = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\n",
    "\n",
    "def new_exp_features(df):\n",
    "    df[\"Total Expenditure\"] = df[exp_cols].sum(axis=1)\n",
    "    df[\"No Spending\"] = (df[\"Total Expenditure\"]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_exp_features(train_df)\n",
    "new_exp_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing: Total Expenditure\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.histplot(x=\"Total Expenditure\", hue=\"Transported\", data=train_df, palette=\"Set1\",bins=200)\n",
    "plt.ylim(0,200)\n",
    "plt.xlim(0,10000)\n",
    "plt.title(\"Total Expenditure Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some analysis on Total Expenditure\n",
    "mean = round(train_df[\"Total Expenditure\"].mean())\n",
    "median = train_df[\"Total Expenditure\"].median()\n",
    "\n",
    "print(\"Mean value of Total Expenditure feature is = \",mean)\n",
    "print(\"Median value of Total Expenditure feature is = \",median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Total Expenditure --> Expenditure Category\n",
    "def expenditure_category(df):\n",
    "    expense_category = []\n",
    "    \n",
    "    for i in df[\"Total Expenditure\"]:\n",
    "        if i==0:\n",
    "            expense_category.append(\"No Expense\")\n",
    "        elif (i>0 and i<=716):\n",
    "            expense_category.append(\"Low Expense\")\n",
    "        elif (i>716 and i<=1441):\n",
    "            expense_category.append(\"Medium Expense\")\n",
    "        elif (i>1441):\n",
    "            expense_category.append(\"High Expense\")\n",
    "    \n",
    "    df[\"Expenditure Category\"] = expense_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure_category(train_df)\n",
    "expenditure_category(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing: No Spending, Expenditure Category\n",
    "cols = [\"No Spending\", \"Expenditure Category\"]\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "for idx,column in enumerate(cols):\n",
    "    plt.subplot(1,2,idx+1)\n",
    "    sns.countplot(x=column, hue=\"Transported\", data=train_df, palette=\"Set2\")\n",
    "    plt.title(f\"{column} Distribution\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#III Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass_df = test_df[[\"PassengerId\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"PassengerId\",\"Cabin\",\"Name\"]\n",
    "train_df.drop(columns =cols, inplace=True)\n",
    "test_df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = train_df.select_dtypes(include=[\"object\",\"bool\"]).columns.tolist()\n",
    "cat_cols.remove(\"Transported\")\n",
    "num_cols = train_df.select_dtypes(include=[\"int\",\"float\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Categorical Columns:\",cat_cols)\n",
    "print(\"\\nNumerical Columns:\",num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missingno(df):\n",
    "    imputer1 = SimpleImputer(strategy=\"most_frequent\")     ##To fill Categorical Features.\n",
    "    imputer2 = SimpleImputer(strategy=\"median\")            ##To fill numeircal features.\n",
    "    df[cat_cols] = imputer1.fit_transform(df[cat_cols])\n",
    "    df[num_cols] = imputer2.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missingno(train_df)\n",
    "fill_missingno(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of missing values for each column\n",
    "missing_values = train_df.isnull().sum()\n",
    "print(\"Number of missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicate values\n",
    "print(\"Duplicate values in training data is: \",train_df.duplicated())\n",
    "print(\"Duplicate values in training data is: \",train_df.duplicated().sum())\n",
    "print(\"Duplicate values in testing data is: \",test_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"CryoSleep\",\"VIP\",\"Travelling_Solo\",\"No Spending\",\"Cabin_Region1\",\"Cabin_Region2\",\"Cabin_Region3\",\"Cabin_Region4\",\n",
    "       \"Cabin_Region5\",\"Cabin_Region6\"]\n",
    "\n",
    "train_df[cols] = train_df[cols].astype(bool)\n",
    "test_df[cols] = test_df[cols].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_cat_cols = [\"HomePlanet\",\"Destination\"]\n",
    "ordinal_cat_cols = [\"CryoSleep\",\"VIP\",\"Travelling_Solo\",\"Cabin_Deck\",\"Cabin_Side\",\"Cabin_Region1\",\"Cabin_Region2\",\n",
    "                    \"Cabin_Region3\",\"Cabin_Region4\",\"Cabin_Region5\",\"Cabin_Region6\",\"Age Group\",\"No Spending\",\n",
    "                    \"Expenditure Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IV Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[ordinal_cat_cols] = train_df[ordinal_cat_cols].apply(enc.fit_transform)\n",
    "test_df[ordinal_cat_cols] = test_df[ordinal_cat_cols].apply(enc.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df,columns=nominal_cat_cols)\n",
    "test_df = pd.get_dummies(test_df,columns=nominal_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Transported\"] = train_df[\"Transported\"].replace({False: 0, True: 1}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=[\"Transported\"])\n",
    "y = train_df[[\"Transported\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "test_df_scaled = scaler.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X_scaled,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VI Model Selection\n",
    "\n",
    "\n",
    "#Hyperparameter tuning, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = []\n",
    "testing_score = []\n",
    "def model_prediction(model):\n",
    "    model.fit(x_train1,y_train1)\n",
    "    x_train_pred1 = model.predict(x_train1)\n",
    "    x_test_pred1 = model.predict(x_test1)\n",
    "    a = accuracy_score(y_train1,x_train_pred1)*100\n",
    "    b = accuracy_score(y_test1,x_test_pred1)*100\n",
    "    training_score.append(a)\n",
    "    testing_score.append(b)\n",
    "    \n",
    "    print(f\"Accuracy_Score of {model} model on Training Data is:\",a)\n",
    "    print(f\"Accuracy_Score of {model} model on Testing Data is:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model):\n",
    "    model.fit(x_train,y_train)\n",
    "    x_train_pred = model.predict(x_train)\n",
    "    x_test_pred = model.predict(x_test)\n",
    "    a = accuracy_score(y_train,x_train_pred)*100\n",
    "    b = accuracy_score(y_test,x_test_pred)*100\n",
    "    training_score.append(a)\n",
    "    testing_score.append(b)\n",
    "    \n",
    "    print(f\"Accuracy_Score of {model} model on Training Data is:\",a)\n",
    "    print(f\"Accuracy_Score of {model} model on Testing Data is:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction(XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Logistic Regression\",\"KNN\",\"Decision Tree\",\"Random Forest\",\"XGBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Algorithms\":models,\n",
    "                   \"Training Score\":training_score,\n",
    "                   \"Testing Score\":testing_score})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x=\"Algorithms\",y=[\"Training Score\",\"Testing Score\"], figsize=(16,6),kind=\"bar\",\n",
    "        title=\"Performance Visualization of Different Models\",colormap=\"Set1\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
